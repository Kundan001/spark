{"cells":[{"cell_type":"markdown","source":["## Quick Start Using Python\n* Using a Databricks notebook to showcase DataFrame operations using Python\n* Reference http://spark.apache.org/docs/latest/quick-start.html"],"metadata":{}},{"cell_type":"code","source":["# Take a look at the file system\ndisplay(dbutils.fs.ls(\"/databricks-datasets/samples/docs/\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .table-result-container {\n    max-height: 300px;\n    overflow: auto;\n  }\n  table, th, td {\n    border: 1px solid black;\n    border-collapse: collapse;\n  }\n  th, td {\n    padding: 5px;\n  }\n  th {\n    text-align: left;\n  }\n</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>path</th><th>name</th><th>size</th></tr></thead><tbody><tr><td>dbfs:/databricks-datasets/samples/docs/README.md</td><td>README.md</td><td>3137</td></tr></tbody></table></div>"]}}],"execution_count":2},{"cell_type":"markdown","source":["DataFrames have ***transformations***, which return pointers to new DataFrames, and ***actions***, which return values."],"metadata":{}},{"cell_type":"code","source":["# transformation\ntextFile = spark.read.text(\"/databricks-datasets/samples/docs/README.md\")"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":4},{"cell_type":"code","source":["# action\ntextFile.count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">3</span><span class=\"ansired\">]: </span>65\n</div>"]}}],"execution_count":5},{"cell_type":"code","source":["# Output the first line from the text file\ntextFile.first()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">4</span><span class=\"ansired\">]: </span>Row(value=&apos;Welcome to the Spark documentation!&apos;)\n</div>"]}}],"execution_count":6},{"cell_type":"markdown","source":["Now we're using a filter ***transformation*** to return a new DataFrame with a subset of the items in the file."],"metadata":{}},{"cell_type":"code","source":["textFile.columns"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">16</span><span class=\"ansired\">]: </span>[&apos;value&apos;]\n</div>"]}}],"execution_count":8},{"cell_type":"code","source":["# Filter all of the lines within the DataFrame\nlinesWithSpark = textFile.filter(textFile.value.contains(\"Spark\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":9},{"cell_type":"code","source":["from pyspark.sql.functions import col\nlinesWithSpark = textFile.filter(textFile.select(col('value')).contains(\"Spark\"))"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">---------------------------------------------------------------------------</span>\n<span class=\"ansired\">AttributeError</span>                            Traceback (most recent call last)\n<span class=\"ansigreen\">&lt;command-601075291823027&gt;</span> in <span class=\"ansicyan\">&lt;module&gt;</span><span class=\"ansiblue\">()</span>\n<span class=\"ansigreen\">      1</span> <span class=\"ansigreen\">from</span> pyspark<span class=\"ansiyellow\">.</span>sql<span class=\"ansiyellow\">.</span>functions <span class=\"ansigreen\">import</span> col<span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">----&gt; 2</span><span class=\"ansiyellow\"> </span>linesWithSpark <span class=\"ansiyellow\">=</span> textFile<span class=\"ansiyellow\">.</span>filter<span class=\"ansiyellow\">(</span>textFile<span class=\"ansiyellow\">.</span>select<span class=\"ansiyellow\">(</span>col<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&apos;value&apos;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">.</span>contains<span class=\"ansiyellow\">(</span><span class=\"ansiblue\">&quot;Spark&quot;</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansigreen\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansicyan\">__getattr__</span><span class=\"ansiblue\">(self, name)</span>\n<span class=\"ansigreen\">   1323</span>         <span class=\"ansigreen\">if</span> name <span class=\"ansigreen\">not</span> <span class=\"ansigreen\">in</span> self<span class=\"ansiyellow\">.</span>columns<span class=\"ansiyellow\">:</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1324</span>             raise AttributeError(\n<span class=\"ansigreen\">-&gt; 1325</span><span class=\"ansiyellow\">                 &quot;&apos;%s&apos; object has no attribute &apos;%s&apos;&quot; % (self.__class__.__name__, name))\n</span><span class=\"ansigreen\">   1326</span>         jc <span class=\"ansiyellow\">=</span> self<span class=\"ansiyellow\">.</span>_jdf<span class=\"ansiyellow\">.</span>apply<span class=\"ansiyellow\">(</span>name<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n<span class=\"ansigreen\">   1327</span>         <span class=\"ansigreen\">return</span> Column<span class=\"ansiyellow\">(</span>jc<span class=\"ansiyellow\">)</span><span class=\"ansiyellow\"></span>\n\n<span class=\"ansired\">AttributeError</span>: &apos;DataFrame&apos; object has no attribute &apos;contains&apos;</div>"]}}],"execution_count":10},{"cell_type":"markdown","source":["Notice that this completes quickly because it is a transformation but lacks any action.  \n* But when performing the actions below (e.g. count, take) then you will see the executions."],"metadata":{}},{"cell_type":"code","source":["# Perform a count (action) \nlinesWithSpark.count()"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">6</span><span class=\"ansired\">]: </span>12\n</div>"]}}],"execution_count":12},{"cell_type":"code","source":["# Output the first five rows using take\nlinesWithSpark.take(5)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansired\">Out[</span><span class=\"ansired\">8</span><span class=\"ansired\">]: </span>\n[Row(value=&apos;Welcome to the Spark documentation!&apos;),\n Row(value=&apos;This readme will walk you through navigating and building the Spark documentation, which is included&apos;),\n Row(value=&apos;here with the Spark source code. You can also find documentation specific to release versions of&apos;),\n Row(value=&apos;Spark at http://spark.apache.org/documentation.html.&apos;),\n Row(value=&apos;whichever version of Spark you currently have checked out of revision control.&apos;)]\n</div>"]}}],"execution_count":13},{"cell_type":"code","source":["# Output the first five rows using show\nlinesWithSpark.show(5, truncate=False)"],"metadata":{},"outputs":[{"metadata":{},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+----------------------------------------------------------------------------------------------------+\nvalue                                                                                               |\n+----------------------------------------------------------------------------------------------------+\nWelcome to the Spark documentation!                                                                 |\nThis readme will walk you through navigating and building the Spark documentation, which is included|\nhere with the Spark source code. You can also find documentation specific to release versions of    |\nSpark at http://spark.apache.org/documentation.html.                                                |\nwhichever version of Spark you currently have checked out of revision control.                      |\n+----------------------------------------------------------------------------------------------------+\nonly showing top 5 rows\n\n</div>"]}}],"execution_count":14},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":15}],"metadata":{"name":"Quick Start Using Python","notebookId":601075291823011},"nbformat":4,"nbformat_minor":0}
